{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ca89ecb5-6732-4db2-872e-124fb7693503",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "This consolidated Notebook  show off-the-shelf Faster RCNN model in action on a simple video. The simple video in this case is demo.mp4. First, we will fetch Faster RCNN Model from MM Openlab github repository and run the video frames into the model to detect the objects. We calculate the latency and throughput of this inference. Then we will walk through the steps to serve this same model through the Triton Inference Server. This includes the step to convert this model to ONNX model (this is one of the native format that Triton supports) and then organize the converted model into Triton Model Registry and load it into Triton for serving. We will then calculate the latency throughput of the inference through Triton. We do this not to compare how local inference performance against Triton inference instead to highlight steps involved converting a model to be served by Triton server. Actually, the latency comparison between local inference with Triton inference below is not a fair comparison, because the local inference has no overhead besides the local model inference call is asynchronous, where as the Triton Infrence call goes through as a http payload and the inference call in synchronous. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4e8934d-c784-46b9-a420-07d4ff7fb46b",
   "metadata": {},
   "source": [
    "## Download the Simple Video\n",
    "In the following cell we download the video from MM Openlab Github repository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7103c7ad-461e-4d6e-b873-d2e5a58ae978",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2025-07-15 22:58:25--  https://github.com/open-mmlab/mmdetection/blob/main/demo/demo.mp4?raw=true\n",
      "Resolving github.com (github.com)... 140.82.114.4\n",
      "Connecting to github.com (github.com)|140.82.114.4|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://github.com/open-mmlab/mmdetection/raw/refs/heads/main/demo/demo.mp4 [following]\n",
      "--2025-07-15 22:58:25--  https://github.com/open-mmlab/mmdetection/raw/refs/heads/main/demo/demo.mp4\n",
      "Reusing existing connection to github.com:443.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://raw.githubusercontent.com/open-mmlab/mmdetection/refs/heads/main/demo/demo.mp4 [following]\n",
      "--2025-07-15 22:58:25--  https://raw.githubusercontent.com/open-mmlab/mmdetection/refs/heads/main/demo/demo.mp4\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.108.133, 185.199.111.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 297688 (291K) [application/octet-stream]\n",
      "Saving to: ‘demo.mp4’\n",
      "\n",
      "demo.mp4            100%[===================>] 290.71K  --.-KB/s    in 0.1s    \n",
      "\n",
      "2025-07-15 22:58:25 (2.16 MB/s) - ‘demo.mp4’ saved [297688/297688]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://github.com/open-mmlab/mmdetection/blob/main/demo/demo.mp4?raw=true -O demo.mp4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "432099f9-9e2f-4b8b-ab84-b48bd74a6f74",
   "metadata": {},
   "source": [
    "In the following cell, we make a 'temp' directory and move the downloaded .mp4 video to that 'temp' directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e0e10140-6938-4cb0-a742-a1b92ce32a12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘temp’: File exists\n"
     ]
    }
   ],
   "source": [
    "!mkdir temp\n",
    "!mv demo.mp4 temp/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cb8649d-f910-4368-8d81-986d2527b230",
   "metadata": {},
   "source": [
    "## Decode the .mp4 Video\n",
    "\n",
    "The following snippet will decode frame after frame from the .mp4 video and write it to the output directory namely 'video_frames'. And in the following cell, we list the downloaded frames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ac24f807-f7f4-49a6-812c-af42571d665b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "\n",
    "video_path = 'temp/demo.mp4'\n",
    "output_dir = 'video_frames'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "i = 0\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    cv2.imwrite(f\"{output_dir}/frame_{i:03d}.jpg\", frame)\n",
    "    i += 1\n",
    "cap.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78b1af11-de00-403b-9553-144ee4963251",
   "metadata": {},
   "source": [
    "Here we list all the frames we wrote into the video_frames directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a43ecd47-d7a3-4067-8f56-38999960a765",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "frame_000.jpg  frame_014.jpg  frame_028.jpg  frame_042.jpg  frame_056.jpg\n",
      "frame_001.jpg  frame_015.jpg  frame_029.jpg  frame_043.jpg  frame_057.jpg\n",
      "frame_002.jpg  frame_016.jpg  frame_030.jpg  frame_044.jpg  frame_058.jpg\n",
      "frame_003.jpg  frame_017.jpg  frame_031.jpg  frame_045.jpg  frame_059.jpg\n",
      "frame_004.jpg  frame_018.jpg  frame_032.jpg  frame_046.jpg  frame_060.jpg\n",
      "frame_005.jpg  frame_019.jpg  frame_033.jpg  frame_047.jpg  frame_061.jpg\n",
      "frame_006.jpg  frame_020.jpg  frame_034.jpg  frame_048.jpg  frame_062.jpg\n",
      "frame_007.jpg  frame_021.jpg  frame_035.jpg  frame_049.jpg  frame_063.jpg\n",
      "frame_008.jpg  frame_022.jpg  frame_036.jpg  frame_050.jpg  frame_064.jpg\n",
      "frame_009.jpg  frame_023.jpg  frame_037.jpg  frame_051.jpg  frame_065.jpg\n",
      "frame_010.jpg  frame_024.jpg  frame_038.jpg  frame_052.jpg  frame_066.jpg\n",
      "frame_011.jpg  frame_025.jpg  frame_039.jpg  frame_053.jpg\n",
      "frame_012.jpg  frame_026.jpg  frame_040.jpg  frame_054.jpg\n",
      "frame_013.jpg  frame_027.jpg  frame_041.jpg  frame_055.jpg\n"
     ]
    }
   ],
   "source": [
    "!ls video_frames"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d51f5c8-63f1-4ba1-9822-70d0cee8c9dc",
   "metadata": {},
   "source": [
    "## Fetch Faster RCNN Model\n",
    "\n",
    "In the following cell we download the base model, configurations, and checkpoints for the model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ccd2cf94-2732-47f4-8be9-1471b83afef1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2025-07-15 19:48:41--  https://raw.githubusercontent.com/open-mmlab/mmdetection/main/configs/_base_/models/fast-rcnn_r50_fpn.py\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.109.133, 185.199.110.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 2256 (2.2K) [text/plain]\n",
      "Saving to: ‘configs/_base_/models/fast-rcnn_r50_fpn.py.1’\n",
      "\n",
      "fast-rcnn_r50_fpn.p 100%[===================>]   2.20K  --.-KB/s    in 0s      \n",
      "\n",
      "2025-07-15 19:48:42 (57.8 MB/s) - ‘configs/_base_/models/fast-rcnn_r50_fpn.py.1’ saved [2256/2256]\n",
      "\n",
      "--2025-07-15 19:48:42--  https://raw.githubusercontent.com/open-mmlab/mmdetection/main/configs/_base_/datasets/coco_detection.py\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.109.133, 185.199.110.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 3187 (3.1K) [text/plain]\n",
      "Saving to: ‘configs/_base_/datasets/coco_detection.py.1’\n",
      "\n",
      "coco_detection.py.1 100%[===================>]   3.11K  --.-KB/s    in 0s      \n",
      "\n",
      "2025-07-15 19:48:42 (60.9 MB/s) - ‘configs/_base_/datasets/coco_detection.py.1’ saved [3187/3187]\n",
      "\n",
      "--2025-07-15 19:48:42--  https://raw.githubusercontent.com/open-mmlab/mmdetection/main/configs/_base_/schedules/schedule_1x.py\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.109.133, 185.199.110.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 814 [text/plain]\n",
      "Saving to: ‘configs/_base_/schedules/schedule_1x.py.1’\n",
      "\n",
      "schedule_1x.py.1    100%[===================>]     814  --.-KB/s    in 0s      \n",
      "\n",
      "2025-07-15 19:48:42 (61.4 MB/s) - ‘configs/_base_/schedules/schedule_1x.py.1’ saved [814/814]\n",
      "\n",
      "--2025-07-15 19:48:42--  https://raw.githubusercontent.com/open-mmlab/mmdetection/main/configs/_base_/default_runtime.py\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.109.133, 185.199.110.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 759 [text/plain]\n",
      "Saving to: ‘configs/_base_/default_runtime.py.1’\n",
      "\n",
      "default_runtime.py. 100%[===================>]     759  --.-KB/s    in 0s      \n",
      "\n",
      "2025-07-15 19:48:42 (66.6 MB/s) - ‘configs/_base_/default_runtime.py.1’ saved [759/759]\n",
      "\n",
      "--2025-07-15 19:48:43--  https://raw.githubusercontent.com/open-mmlab/mmdetection/main/configs/faster_rcnn/faster-rcnn_r50_fpn_1x_coco.py\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.109.133, 185.199.110.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 177 [text/plain]\n",
      "Saving to: ‘configs/faster_rcnn/faster-rcnn_r50_fpn_1x_coco.py.3’\n",
      "\n",
      "faster-rcnn_r50_fpn 100%[===================>]     177  --.-KB/s    in 0s      \n",
      "\n",
      "2025-07-15 19:48:43 (14.3 MB/s) - ‘configs/faster_rcnn/faster-rcnn_r50_fpn_1x_coco.py.3’ saved [177/177]\n",
      "\n",
      "--2025-07-15 19:48:43--  https://raw.githubusercontent.com/open-mmlab/mmdetection/main/configs/_base_/models/faster-rcnn_r50_fpn.py\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.109.133, 185.199.110.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 3828 (3.7K) [text/plain]\n",
      "Saving to: ‘configs/_base_/models/faster-rcnn_r50_fpn.py.2’\n",
      "\n",
      "faster-rcnn_r50_fpn 100%[===================>]   3.74K  --.-KB/s    in 0s      \n",
      "\n",
      "2025-07-15 19:48:43 (24.5 MB/s) - ‘configs/_base_/models/faster-rcnn_r50_fpn.py.2’ saved [3828/3828]\n",
      "\n",
      "--2025-07-15 19:48:43--  https://download.openmmlab.com/mmdetection/v2.0/faster_rcnn/faster_rcnn_r50_fpn_1x_coco/faster_rcnn_r50_fpn_1x_coco_20200130-047c8118.pth\n",
      "Resolving download.openmmlab.com (download.openmmlab.com)... 163.181.60.226, 163.181.60.221, 163.181.60.225, ...\n",
      "Connecting to download.openmmlab.com (download.openmmlab.com)|163.181.60.226|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 167287506 (160M) [application/octet-stream]\n",
      "Saving to: ‘checkpoints/faster_rcnn_r50_fpn_1x_coco_20200130-047c8118.pth.3’\n",
      "\n",
      "faster_rcnn_r50_fpn 100%[===================>] 159.54M  15.2MB/s    in 10s     \n",
      "\n",
      "2025-07-15 19:48:54 (15.3 MB/s) - ‘checkpoints/faster_rcnn_r50_fpn_1x_coco_20200130-047c8118.pth.3’ saved [167287506/167287506]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create folders\n",
    "!mkdir -p configs/_base_/models\n",
    "!mkdir -p configs/_base_/datasets\n",
    "!mkdir -p configs/_base_/schedules\n",
    "\n",
    "# Download the required base files\n",
    "!wget https://raw.githubusercontent.com/open-mmlab/mmdetection/main/configs/_base_/models/fast-rcnn_r50_fpn.py -P configs/_base_/models/\n",
    "!wget https://raw.githubusercontent.com/open-mmlab/mmdetection/main/configs/_base_/datasets/coco_detection.py -P configs/_base_/datasets/\n",
    "!wget https://raw.githubusercontent.com/open-mmlab/mmdetection/main/configs/_base_/schedules/schedule_1x.py -P configs/_base_/schedules/\n",
    "!wget https://raw.githubusercontent.com/open-mmlab/mmdetection/main/configs/_base_/default_runtime.py -P configs/_base_/\n",
    "\n",
    "!wget https://raw.githubusercontent.com/open-mmlab/mmdetection/main/configs/faster_rcnn/faster-rcnn_r50_fpn_1x_coco.py -P configs/faster_rcnn/\n",
    "!wget https://raw.githubusercontent.com/open-mmlab/mmdetection/main/configs/_base_/models/faster-rcnn_r50_fpn.py -P configs/_base_/models/\n",
    "!wget https://download.openmmlab.com/mmdetection/v2.0/faster_rcnn/faster_rcnn_r50_fpn_1x_coco/faster_rcnn_r50_fpn_1x_coco_20200130-047c8118.pth -P checkpoints/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3848e950-97a6-4639-acae-1f053cc3b812",
   "metadata": {},
   "source": [
    "## Run Inference and Visualize Detections\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a26efa71-d28c-41e1-ab2e-a6c99becbc6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loads checkpoint by local backend from path: checkpoints/faster_rcnn_r50_fpn_1x_coco_20200130-047c8118.pth\n",
      "07/15 19:49:05 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - `Visualizer` backend is not initialized because save_dir is None.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/mmengine/visualization/visualizer.py:741: UserWarning: Warning: The bbox is out of bounds, the drawn bbox may not be in the image\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/mmengine/visualization/visualizer.py:812: UserWarning: Warning: The polygon is out of bounds, the drawn polygon may not be in the image\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import mmcv\n",
    "from mmdet.apis import init_detector, inference_detector\n",
    "from mmdet.visualization import DetLocalVisualizer\n",
    "\n",
    "# Initialize the model\n",
    "config = 'configs/faster_rcnn/faster-rcnn_r50_fpn_1x_coco.py'\n",
    "checkpoint = 'checkpoints/faster_rcnn_r50_fpn_1x_coco_20200130-047c8118.pth'\n",
    "model = init_detector(config, checkpoint, device='cuda:0')\n",
    "\n",
    "# Setup input/output directories\n",
    "input_dir = './video_frames'\n",
    "output_dir = './output_frames'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Set up the visualizer\n",
    "visualizer = DetLocalVisualizer(name='my_vis')\n",
    "visualizer.dataset_meta = model.dataset_meta\n",
    "\n",
    "# Process images\n",
    "for img_name in sorted(os.listdir(input_dir)):\n",
    "    if not img_name.lower().endswith('.jpg'):\n",
    "        continue\n",
    "    img_path = os.path.join(input_dir, img_name)\n",
    "    image = mmcv.imread(img_path)  # Read the actual image array\n",
    "    result = inference_detector(model, image)\n",
    "\n",
    "    out_file = os.path.join(output_dir, img_name)\n",
    "    visualizer.add_datasample(\n",
    "        name=img_name,\n",
    "        image=image,\n",
    "        data_sample=result,\n",
    "        draw_gt=False,\n",
    "        draw_pred=True,\n",
    "        show=False,\n",
    "        wait_time=0,\n",
    "        out_file=out_file\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42e05425-7eb9-4314-a6cb-e0ec8dc85d7e",
   "metadata": {},
   "source": [
    "![f1](./output_frames/frame_000.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a4eb557b-5f71-4e4d-a51e-2ffeda1ead23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loads checkpoint by local backend from path: checkpoints/faster_rcnn_r50_fpn_1x_coco_20200130-047c8118.pth\n",
      "number of runs: 61\n",
      "latency_ms: 89.80352761315517\n",
      "throughput: 11.135420028349884\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import torch\n",
    "\n",
    "# Initialize the model\n",
    "config = 'configs/faster_rcnn/faster-rcnn_r50_fpn_1x_coco.py'\n",
    "checkpoint = 'checkpoints/faster_rcnn_r50_fpn_1x_coco_20200130-047c8118.pth'\n",
    "model = init_detector(config, checkpoint, device='cuda:0')\n",
    "\n",
    "\n",
    "# Setup input/output directories\n",
    "input_dir = './video_frames'\n",
    "output_dir = './output_frames'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Process images\n",
    "img_cnt = 1\n",
    "warmup_cnt = 6\n",
    "for img_name in sorted(os.listdir(input_dir)):\n",
    "    if not img_name.lower().endswith('.jpg'):\n",
    "        continue\n",
    "    img_cnt += 1\n",
    "    if img_cnt <= warmup_cnt:\n",
    "        continue\n",
    "    if img_cnt == (warmup_cnt+1):\n",
    "        start = time.time()\n",
    "    img_path = os.path.join(input_dir, img_name)\n",
    "    image = mmcv.imread(img_path)  # Read the actual image array\n",
    "    result = inference_detector(model, image)\n",
    "    \n",
    "torch.cuda.synchronize()  # Important!\n",
    "end = time.time()\n",
    "\n",
    "n_runs = (img_cnt-warmup_cnt-1)\n",
    "print('number of runs:', n_runs)\n",
    "\n",
    "latency_ms = (end - start) / n_runs * 1000\n",
    "throughput = n_runs / (end - start)\n",
    "\n",
    "print('latency_ms:', latency_ms)\n",
    "print('throughput:', throughput)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7576c18d-14b9-4d62-bba4-1f135e780ce3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "07/15 19:55:00 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - torch2onnx: \n",
      "\tmodel_cfg: configs/faster_rcnn/faster-rcnn_r50_fpn_1x_coco.py \n",
      "\tdeploy_cfg: /mmdeploy/configs/mmdet/detection/detection_onnxruntime_dynamic.py\n",
      "07/15 19:55:01 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - Failed to search registry with scope \"mmdet\" in the \"Codebases\" registry tree. As a workaround, the current \"Codebases\" registry in \"mmdeploy\" is used to build instance. This may cause unexpected failure when running the built modules. Please check whether \"mmdet\" is a correct scope, or whether the registry is initialized.\n",
      "07/15 19:55:01 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - Failed to search registry with scope \"mmdet\" in the \"mmdet_tasks\" registry tree. As a workaround, the current \"mmdet_tasks\" registry in \"mmdeploy\" is used to build instance. This may cause unexpected failure when running the built modules. Please check whether \"mmdet\" is a correct scope, or whether the registry is initialized.\n",
      "Loads checkpoint by local backend from path: checkpoints/faster_rcnn_r50_fpn_1x_coco_20200130-047c8118.pth\n",
      "07/15 19:55:01 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - DeprecationWarning: get_onnx_config will be deprecated in the future. \n",
      "07/15 19:55:01 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Export PyTorch model to ONNX: output_models/end2end.onnx.\n",
      "/mmdeploy/mmdeploy/core/optimizers/function_marker.py:160: TracerWarning: Converting a tensor to a Python integer might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  ys_shape = tuple(int(s) for s in ys.shape)\n",
      "/usr/local/lib/python3.10/dist-packages/mmdet/models/dense_heads/anchor_head.py:115: UserWarning: DeprecationWarning: anchor_generator is deprecated, please use \"prior_generator\" instead\n",
      "  warnings.warn('DeprecationWarning: anchor_generator is deprecated, '\n",
      "/usr/local/lib/python3.10/dist-packages/mmdet/models/task_modules/prior_generators/anchor_generator.py:356: UserWarning: ``grid_anchors`` would be deprecated soon. Please use ``grid_priors`` \n",
      "  warnings.warn('``grid_anchors`` would be deprecated soon. '\n",
      "/usr/local/lib/python3.10/dist-packages/mmdet/models/task_modules/prior_generators/anchor_generator.py:392: UserWarning: ``single_level_grid_anchors`` would be deprecated soon. Please use ``single_level_grid_priors`` \n",
      "  warnings.warn(\n",
      "/mmdeploy/mmdeploy/codebase/mmdet/models/dense_heads/rpn_head.py:89: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  assert cls_score.size()[-2:] == bbox_pred.size()[-2:]\n",
      "/mmdeploy/mmdeploy/pytorch/functions/topk.py:28: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.\n",
      "  k = torch.tensor(k, device=input.device, dtype=torch.long)\n",
      "/mmdeploy/mmdeploy/codebase/mmdet/models/task_modules/coders/delta_xywh_bbox_coder.py:38: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  assert pred_bboxes.size(0) == bboxes.size(0)\n",
      "/mmdeploy/mmdeploy/codebase/mmdet/models/task_modules/coders/delta_xywh_bbox_coder.py:40: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  assert pred_bboxes.size(1) == bboxes.size(1)\n",
      "/mmdeploy/mmdeploy/codebase/mmdet/deploy/utils.py:48: TracerWarning: Using len to get tensor shape might cause the trace to be incorrect. Recommended usage would be tensor.shape[0]. Passing a tensor of different shape might lead to errors or silently give incorrect results.\n",
      "  assert len(max_shape) == 2, '`max_shape` should be [h, w]'\n",
      "/mmdeploy/mmdeploy/mmcv/ops/nms.py:285: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.\n",
      "  iou_threshold = torch.tensor([iou_threshold], dtype=torch.float32)\n",
      "/mmdeploy/mmdeploy/mmcv/ops/nms.py:286: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.\n",
      "  score_threshold = torch.tensor([score_threshold], dtype=torch.float32)\n",
      "/mmdeploy/mmdeploy/mmcv/ops/nms.py:44: TracerWarning: Converting a tensor to a Python float might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  score_threshold = float(score_threshold)\n",
      "/mmdeploy/mmdeploy/mmcv/ops/nms.py:45: TracerWarning: Converting a tensor to a Python float might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  iou_threshold = float(iou_threshold)\n",
      "/mmcv/mmcv/ops/nms.py:123: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  assert boxes.size(1) == 4\n",
      "/mmcv/mmcv/ops/nms.py:124: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  assert boxes.size(0) == scores.size(0)\n",
      "/mmdeploy/mmdeploy/codebase/mmdet/models/roi_heads/standard_roi_head.py:41: TracerWarning: Converting a tensor to a Python integer might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  rois_dims = int(rois.shape[-1])\n",
      "/mmcv/mmcv/ops/roi_align.py:78: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  assert rois.size(1) == 5, 'RoI must be (idx, x1, y1, x2, y2)!'\n",
      "/usr/local/lib/python3.10/dist-packages/torch/onnx/symbolic_opset9.py:5589: UserWarning: Exporting aten::index operator of advanced indexing in opset 11 is achieved by combination of multiple ONNX operators, including Reshape, Transpose, Concat, and Gather. If indices include negative values, the exported graph will produce incorrect results.\n",
      "  warnings.warn(\n",
      "/mmdeploy/mmdeploy/mmcv/ops/roi_align.py:61: FutureWarning: 'torch.onnx.symbolic_opset9._cast_Long' is deprecated in version 2.0 and will be removed in the future. Please Avoid using this function and create a Cast node instead.\n",
      "  batch_indices = _cast_Long(\n",
      "07/15 19:55:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Execute onnx optimize passes.\n",
      "============= Diagnostic Run torch.onnx.export version 2.0.0+cu118 =============\n",
      "verbose: False, log level: Level.ERROR\n",
      "======================= 0 NONE 0 NOTE 0 WARNING 0 ERROR ========================\n",
      "\n",
      "07/15 19:55:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - torch2onnx finished. Results saved to output_models\n"
     ]
    }
   ],
   "source": [
    "!python /mmdeploy/tools/torch2onnx.py /mmdeploy/configs/mmdet/detection/detection_onnxruntime_dynamic.py configs/faster_rcnn/faster-rcnn_r50_fpn_1x_coco.py checkpoints/faster_rcnn_r50_fpn_1x_coco_20200130-047c8118.pth video_frames/frame_000.jpg --device cuda --work-dir output_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d8c62123-e97f-4e78-8a00-853a4292a79f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "end2end.onnx\n"
     ]
    }
   ],
   "source": [
    "!ls output_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b33a115f-ca36-4bdd-808f-f108c5408af9",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mv output_models/end2end.onnx output_models/model.onnx\n",
    "!chmod 744 create_model_repo.sh "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a57c7b04-248a-4ee5-9579-b2fc6cd98b45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1280, 720)\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "\n",
    "img = Image.open(\"video_frames/frame_000.jpg\")\n",
    "print(img.size)  # (width, height)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "738e5b69-1860-4986-a9d0-73e755d93625",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inputs:\n",
      "input [0, 3, 0, 0]\n",
      "Outputs:\n",
      "dets [0, 0, 0]\n",
      "labels [0, 0]\n"
     ]
    }
   ],
   "source": [
    "import onnx\n",
    "\n",
    "model = onnx.load(\"output_models/model.onnx\")\n",
    "print(\"Inputs:\")\n",
    "for input in model.graph.input:\n",
    "    print(input.name, [dim.dim_value for dim in input.type.tensor_type.shape.dim])\n",
    "\n",
    "print(\"Outputs:\")\n",
    "for output in model.graph.output:\n",
    "    print(output.name, [dim.dim_value for dim in output.type.tensor_type.shape.dim])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "204b75f8-01c5-4d90-aeaf-3dfb87eb51dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Model repository created successfully in: model_repository\n"
     ]
    }
   ],
   "source": [
    "!./create_model_repo.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef6743f8-b1c2-48de-9b5b-5ca67bfe291b",
   "metadata": {},
   "source": [
    "### Now go ahead and start the triton server before running the next cell\n",
    "```\n",
    "tritonserver --model-repository=/workspace/model_repository/ --log-verbose=1\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8b5c8303-2225-4fb8-9bf7-8303ca4a8b83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of runs: 61\n",
      "Latency per image: 132.03 ms\n",
      "Throughput: 7.57 FPS\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tritonclient.http as httpclient\n",
    "\n",
    "# Create Triton client\n",
    "client = httpclient.InferenceServerClient(\"localhost:8000\")\n",
    "\n",
    "# Setup input/output directories\n",
    "input_dir = './video_frames'\n",
    "output_dir = './output_frames'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Model name in Triton\n",
    "model_name = \"faster_rcnn\"\n",
    "\n",
    "# Processing variables\n",
    "img_cnt = 1\n",
    "warmup_cnt = 6\n",
    "\n",
    "total_end_minus_start = 0\n",
    "\n",
    "# Loop through images\n",
    "for img_name in sorted(os.listdir(input_dir)):\n",
    "    if not img_name.lower().endswith('.jpg'):\n",
    "        continue\n",
    "\n",
    "    img_cnt += 1\n",
    "    if img_cnt <= warmup_cnt:\n",
    "        continue\n",
    "\n",
    "    img_path = os.path.join(input_dir, img_name)\n",
    "    image = mmcv.imread(img_path)  # Read image, shape (H, W, C)\n",
    "\n",
    "    # Preprocess: keep original size\n",
    "    input_data = image.astype(np.float32)\n",
    "    input_data = np.transpose(input_data, (2, 0, 1))  # HWC -> CHW\n",
    "    input_data = np.expand_dims(input_data, axis=0)   # Add batch dim: (1, C, H, W)\n",
    "\n",
    "    # Create Triton input\n",
    "    inputs = [httpclient.InferInput(\"input\", input_data.shape, \"FP32\")]\n",
    "    inputs[0].set_data_from_numpy(input_data)\n",
    "\n",
    "    # Create output request\n",
    "    outputs = [httpclient.InferRequestedOutput(\"dets\"),\n",
    "               httpclient.InferRequestedOutput(\"labels\")]\n",
    "\n",
    "    # Inference timing\n",
    "    start = time.time()\n",
    "    response = client.infer(model_name, inputs=inputs, outputs=outputs)\n",
    "    # If you do any local torch work, synchronize here:\n",
    "    # torch.cuda.synchronize()\n",
    "    end = time.time()\n",
    "\n",
    "    total_end_minus_start += (end - start)\n",
    "\n",
    "    # Extract results\n",
    "    dets = response.as_numpy(\"dets\")\n",
    "    labels = response.as_numpy(\"labels\")\n",
    "\n",
    "    #print(f\"Image {img_name}: dets shape={dets.shape}, labels shape={labels.shape}\")\n",
    "\n",
    "# Compute statistics\n",
    "n_runs = (img_cnt - warmup_cnt - 1)\n",
    "print(\"number of runs:\", n_runs)\n",
    "\n",
    "latency_ms = total_end_minus_start / n_runs * 1000\n",
    "throughput = n_runs / total_end_minus_start\n",
    "\n",
    "print(f\"Latency per image: {latency_ms:.2f} ms\")\n",
    "print(f\"Throughput: {throughput:.2f} FPS\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c98e5926-4352-45c0-89f4-a7bd1a7dc324",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing image: frame_000.jpg, shape: (720, 1280, 3)\n",
      "Input data shape (NCHW): (1, 3, 720, 1280)\n",
      "After reshape dets shape: (43, 5)\n",
      "After reshape labels shape: (43,)\n",
      "Processing image: frame_001.jpg, shape: (720, 1280, 3)\n",
      "Input data shape (NCHW): (1, 3, 720, 1280)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/mmengine/visualization/visualizer.py:741: UserWarning: Warning: The bbox is out of bounds, the drawn bbox may not be in the image\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/mmengine/visualization/visualizer.py:812: UserWarning: Warning: The polygon is out of bounds, the drawn polygon may not be in the image\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After reshape dets shape: (53, 5)\n",
      "After reshape labels shape: (53,)\n",
      "Processing image: frame_002.jpg, shape: (720, 1280, 3)\n",
      "Input data shape (NCHW): (1, 3, 720, 1280)\n",
      "After reshape dets shape: (41, 5)\n",
      "After reshape labels shape: (41,)\n",
      "Processing image: frame_003.jpg, shape: (720, 1280, 3)\n",
      "Input data shape (NCHW): (1, 3, 720, 1280)\n",
      "After reshape dets shape: (46, 5)\n",
      "After reshape labels shape: (46,)\n",
      "Processing image: frame_004.jpg, shape: (720, 1280, 3)\n",
      "Input data shape (NCHW): (1, 3, 720, 1280)\n",
      "After reshape dets shape: (56, 5)\n",
      "After reshape labels shape: (56,)\n",
      "Processing image: frame_005.jpg, shape: (720, 1280, 3)\n",
      "Input data shape (NCHW): (1, 3, 720, 1280)\n",
      "After reshape dets shape: (53, 5)\n",
      "After reshape labels shape: (53,)\n",
      "Processing image: frame_006.jpg, shape: (720, 1280, 3)\n",
      "Input data shape (NCHW): (1, 3, 720, 1280)\n",
      "After reshape dets shape: (56, 5)\n",
      "After reshape labels shape: (56,)\n",
      "Processing image: frame_007.jpg, shape: (720, 1280, 3)\n",
      "Input data shape (NCHW): (1, 3, 720, 1280)\n",
      "After reshape dets shape: (53, 5)\n",
      "After reshape labels shape: (53,)\n",
      "Processing image: frame_008.jpg, shape: (720, 1280, 3)\n",
      "Input data shape (NCHW): (1, 3, 720, 1280)\n",
      "After reshape dets shape: (45, 5)\n",
      "After reshape labels shape: (45,)\n",
      "Processing image: frame_009.jpg, shape: (720, 1280, 3)\n",
      "Input data shape (NCHW): (1, 3, 720, 1280)\n",
      "After reshape dets shape: (42, 5)\n",
      "After reshape labels shape: (42,)\n",
      "Processing image: frame_010.jpg, shape: (720, 1280, 3)\n",
      "Input data shape (NCHW): (1, 3, 720, 1280)\n",
      "After reshape dets shape: (43, 5)\n",
      "After reshape labels shape: (43,)\n",
      "Processing image: frame_011.jpg, shape: (720, 1280, 3)\n",
      "Input data shape (NCHW): (1, 3, 720, 1280)\n",
      "After reshape dets shape: (39, 5)\n",
      "After reshape labels shape: (39,)\n",
      "Processing image: frame_012.jpg, shape: (720, 1280, 3)\n",
      "Input data shape (NCHW): (1, 3, 720, 1280)\n",
      "After reshape dets shape: (40, 5)\n",
      "After reshape labels shape: (40,)\n",
      "Processing image: frame_013.jpg, shape: (720, 1280, 3)\n",
      "Input data shape (NCHW): (1, 3, 720, 1280)\n",
      "After reshape dets shape: (37, 5)\n",
      "After reshape labels shape: (37,)\n",
      "Processing image: frame_014.jpg, shape: (720, 1280, 3)\n",
      "Input data shape (NCHW): (1, 3, 720, 1280)\n",
      "After reshape dets shape: (36, 5)\n",
      "After reshape labels shape: (36,)\n",
      "Processing image: frame_015.jpg, shape: (720, 1280, 3)\n",
      "Input data shape (NCHW): (1, 3, 720, 1280)\n",
      "After reshape dets shape: (38, 5)\n",
      "After reshape labels shape: (38,)\n",
      "Processing image: frame_016.jpg, shape: (720, 1280, 3)\n",
      "Input data shape (NCHW): (1, 3, 720, 1280)\n",
      "After reshape dets shape: (35, 5)\n",
      "After reshape labels shape: (35,)\n",
      "Processing image: frame_017.jpg, shape: (720, 1280, 3)\n",
      "Input data shape (NCHW): (1, 3, 720, 1280)\n",
      "After reshape dets shape: (38, 5)\n",
      "After reshape labels shape: (38,)\n",
      "Processing image: frame_018.jpg, shape: (720, 1280, 3)\n",
      "Input data shape (NCHW): (1, 3, 720, 1280)\n",
      "After reshape dets shape: (42, 5)\n",
      "After reshape labels shape: (42,)\n",
      "Processing image: frame_019.jpg, shape: (720, 1280, 3)\n",
      "Input data shape (NCHW): (1, 3, 720, 1280)\n",
      "After reshape dets shape: (31, 5)\n",
      "After reshape labels shape: (31,)\n",
      "Processing image: frame_020.jpg, shape: (720, 1280, 3)\n",
      "Input data shape (NCHW): (1, 3, 720, 1280)\n",
      "After reshape dets shape: (38, 5)\n",
      "After reshape labels shape: (38,)\n",
      "Processing image: frame_021.jpg, shape: (720, 1280, 3)\n",
      "Input data shape (NCHW): (1, 3, 720, 1280)\n",
      "After reshape dets shape: (39, 5)\n",
      "After reshape labels shape: (39,)\n",
      "Processing image: frame_022.jpg, shape: (720, 1280, 3)\n",
      "Input data shape (NCHW): (1, 3, 720, 1280)\n",
      "After reshape dets shape: (44, 5)\n",
      "After reshape labels shape: (44,)\n",
      "Processing image: frame_023.jpg, shape: (720, 1280, 3)\n",
      "Input data shape (NCHW): (1, 3, 720, 1280)\n",
      "After reshape dets shape: (47, 5)\n",
      "After reshape labels shape: (47,)\n",
      "Processing image: frame_024.jpg, shape: (720, 1280, 3)\n",
      "Input data shape (NCHW): (1, 3, 720, 1280)\n",
      "After reshape dets shape: (39, 5)\n",
      "After reshape labels shape: (39,)\n",
      "Processing image: frame_025.jpg, shape: (720, 1280, 3)\n",
      "Input data shape (NCHW): (1, 3, 720, 1280)\n",
      "After reshape dets shape: (36, 5)\n",
      "After reshape labels shape: (36,)\n",
      "Processing image: frame_026.jpg, shape: (720, 1280, 3)\n",
      "Input data shape (NCHW): (1, 3, 720, 1280)\n",
      "After reshape dets shape: (39, 5)\n",
      "After reshape labels shape: (39,)\n",
      "Processing image: frame_027.jpg, shape: (720, 1280, 3)\n",
      "Input data shape (NCHW): (1, 3, 720, 1280)\n",
      "After reshape dets shape: (40, 5)\n",
      "After reshape labels shape: (40,)\n",
      "Processing image: frame_028.jpg, shape: (720, 1280, 3)\n",
      "Input data shape (NCHW): (1, 3, 720, 1280)\n",
      "After reshape dets shape: (35, 5)\n",
      "After reshape labels shape: (35,)\n",
      "Processing image: frame_029.jpg, shape: (720, 1280, 3)\n",
      "Input data shape (NCHW): (1, 3, 720, 1280)\n",
      "After reshape dets shape: (45, 5)\n",
      "After reshape labels shape: (45,)\n",
      "Processing image: frame_030.jpg, shape: (720, 1280, 3)\n",
      "Input data shape (NCHW): (1, 3, 720, 1280)\n",
      "After reshape dets shape: (38, 5)\n",
      "After reshape labels shape: (38,)\n",
      "Processing image: frame_031.jpg, shape: (720, 1280, 3)\n",
      "Input data shape (NCHW): (1, 3, 720, 1280)\n",
      "After reshape dets shape: (39, 5)\n",
      "After reshape labels shape: (39,)\n",
      "Processing image: frame_032.jpg, shape: (720, 1280, 3)\n",
      "Input data shape (NCHW): (1, 3, 720, 1280)\n",
      "After reshape dets shape: (32, 5)\n",
      "After reshape labels shape: (32,)\n",
      "Processing image: frame_033.jpg, shape: (720, 1280, 3)\n",
      "Input data shape (NCHW): (1, 3, 720, 1280)\n",
      "After reshape dets shape: (31, 5)\n",
      "After reshape labels shape: (31,)\n",
      "Processing image: frame_034.jpg, shape: (720, 1280, 3)\n",
      "Input data shape (NCHW): (1, 3, 720, 1280)\n",
      "After reshape dets shape: (40, 5)\n",
      "After reshape labels shape: (40,)\n",
      "Processing image: frame_035.jpg, shape: (720, 1280, 3)\n",
      "Input data shape (NCHW): (1, 3, 720, 1280)\n",
      "After reshape dets shape: (39, 5)\n",
      "After reshape labels shape: (39,)\n",
      "Processing image: frame_036.jpg, shape: (720, 1280, 3)\n",
      "Input data shape (NCHW): (1, 3, 720, 1280)\n",
      "After reshape dets shape: (35, 5)\n",
      "After reshape labels shape: (35,)\n",
      "Processing image: frame_037.jpg, shape: (720, 1280, 3)\n",
      "Input data shape (NCHW): (1, 3, 720, 1280)\n",
      "After reshape dets shape: (34, 5)\n",
      "After reshape labels shape: (34,)\n",
      "Processing image: frame_038.jpg, shape: (720, 1280, 3)\n",
      "Input data shape (NCHW): (1, 3, 720, 1280)\n",
      "After reshape dets shape: (33, 5)\n",
      "After reshape labels shape: (33,)\n",
      "Processing image: frame_039.jpg, shape: (720, 1280, 3)\n",
      "Input data shape (NCHW): (1, 3, 720, 1280)\n",
      "After reshape dets shape: (37, 5)\n",
      "After reshape labels shape: (37,)\n",
      "Processing image: frame_040.jpg, shape: (720, 1280, 3)\n",
      "Input data shape (NCHW): (1, 3, 720, 1280)\n",
      "After reshape dets shape: (36, 5)\n",
      "After reshape labels shape: (36,)\n",
      "Processing image: frame_041.jpg, shape: (720, 1280, 3)\n",
      "Input data shape (NCHW): (1, 3, 720, 1280)\n",
      "After reshape dets shape: (39, 5)\n",
      "After reshape labels shape: (39,)\n",
      "Processing image: frame_042.jpg, shape: (720, 1280, 3)\n",
      "Input data shape (NCHW): (1, 3, 720, 1280)\n",
      "After reshape dets shape: (40, 5)\n",
      "After reshape labels shape: (40,)\n",
      "Processing image: frame_043.jpg, shape: (720, 1280, 3)\n",
      "Input data shape (NCHW): (1, 3, 720, 1280)\n",
      "After reshape dets shape: (36, 5)\n",
      "After reshape labels shape: (36,)\n",
      "Processing image: frame_044.jpg, shape: (720, 1280, 3)\n",
      "Input data shape (NCHW): (1, 3, 720, 1280)\n",
      "After reshape dets shape: (36, 5)\n",
      "After reshape labels shape: (36,)\n",
      "Processing image: frame_045.jpg, shape: (720, 1280, 3)\n",
      "Input data shape (NCHW): (1, 3, 720, 1280)\n",
      "After reshape dets shape: (37, 5)\n",
      "After reshape labels shape: (37,)\n",
      "Processing image: frame_046.jpg, shape: (720, 1280, 3)\n",
      "Input data shape (NCHW): (1, 3, 720, 1280)\n",
      "After reshape dets shape: (35, 5)\n",
      "After reshape labels shape: (35,)\n",
      "Processing image: frame_047.jpg, shape: (720, 1280, 3)\n",
      "Input data shape (NCHW): (1, 3, 720, 1280)\n",
      "After reshape dets shape: (40, 5)\n",
      "After reshape labels shape: (40,)\n",
      "Processing image: frame_048.jpg, shape: (720, 1280, 3)\n",
      "Input data shape (NCHW): (1, 3, 720, 1280)\n",
      "After reshape dets shape: (43, 5)\n",
      "After reshape labels shape: (43,)\n",
      "Processing image: frame_049.jpg, shape: (720, 1280, 3)\n",
      "Input data shape (NCHW): (1, 3, 720, 1280)\n",
      "After reshape dets shape: (38, 5)\n",
      "After reshape labels shape: (38,)\n",
      "Processing image: frame_050.jpg, shape: (720, 1280, 3)\n",
      "Input data shape (NCHW): (1, 3, 720, 1280)\n",
      "After reshape dets shape: (35, 5)\n",
      "After reshape labels shape: (35,)\n",
      "Processing image: frame_051.jpg, shape: (720, 1280, 3)\n",
      "Input data shape (NCHW): (1, 3, 720, 1280)\n",
      "After reshape dets shape: (39, 5)\n",
      "After reshape labels shape: (39,)\n",
      "Processing image: frame_052.jpg, shape: (720, 1280, 3)\n",
      "Input data shape (NCHW): (1, 3, 720, 1280)\n",
      "After reshape dets shape: (33, 5)\n",
      "After reshape labels shape: (33,)\n",
      "Processing image: frame_053.jpg, shape: (720, 1280, 3)\n",
      "Input data shape (NCHW): (1, 3, 720, 1280)\n",
      "After reshape dets shape: (35, 5)\n",
      "After reshape labels shape: (35,)\n",
      "Processing image: frame_054.jpg, shape: (720, 1280, 3)\n",
      "Input data shape (NCHW): (1, 3, 720, 1280)\n",
      "After reshape dets shape: (31, 5)\n",
      "After reshape labels shape: (31,)\n",
      "Processing image: frame_055.jpg, shape: (720, 1280, 3)\n",
      "Input data shape (NCHW): (1, 3, 720, 1280)\n",
      "After reshape dets shape: (32, 5)\n",
      "After reshape labels shape: (32,)\n",
      "Processing image: frame_056.jpg, shape: (720, 1280, 3)\n",
      "Input data shape (NCHW): (1, 3, 720, 1280)\n",
      "After reshape dets shape: (29, 5)\n",
      "After reshape labels shape: (29,)\n",
      "Processing image: frame_057.jpg, shape: (720, 1280, 3)\n",
      "Input data shape (NCHW): (1, 3, 720, 1280)\n",
      "After reshape dets shape: (35, 5)\n",
      "After reshape labels shape: (35,)\n",
      "Processing image: frame_058.jpg, shape: (720, 1280, 3)\n",
      "Input data shape (NCHW): (1, 3, 720, 1280)\n",
      "After reshape dets shape: (36, 5)\n",
      "After reshape labels shape: (36,)\n",
      "Processing image: frame_059.jpg, shape: (720, 1280, 3)\n",
      "Input data shape (NCHW): (1, 3, 720, 1280)\n",
      "After reshape dets shape: (32, 5)\n",
      "After reshape labels shape: (32,)\n",
      "Processing image: frame_060.jpg, shape: (720, 1280, 3)\n",
      "Input data shape (NCHW): (1, 3, 720, 1280)\n",
      "After reshape dets shape: (30, 5)\n",
      "After reshape labels shape: (30,)\n",
      "Processing image: frame_061.jpg, shape: (720, 1280, 3)\n",
      "Input data shape (NCHW): (1, 3, 720, 1280)\n",
      "After reshape dets shape: (36, 5)\n",
      "After reshape labels shape: (36,)\n",
      "Processing image: frame_062.jpg, shape: (720, 1280, 3)\n",
      "Input data shape (NCHW): (1, 3, 720, 1280)\n",
      "After reshape dets shape: (38, 5)\n",
      "After reshape labels shape: (38,)\n",
      "Processing image: frame_063.jpg, shape: (720, 1280, 3)\n",
      "Input data shape (NCHW): (1, 3, 720, 1280)\n",
      "After reshape dets shape: (39, 5)\n",
      "After reshape labels shape: (39,)\n",
      "Processing image: frame_064.jpg, shape: (720, 1280, 3)\n",
      "Input data shape (NCHW): (1, 3, 720, 1280)\n",
      "After reshape dets shape: (39, 5)\n",
      "After reshape labels shape: (39,)\n",
      "Processing image: frame_065.jpg, shape: (720, 1280, 3)\n",
      "Input data shape (NCHW): (1, 3, 720, 1280)\n",
      "After reshape dets shape: (37, 5)\n",
      "After reshape labels shape: (37,)\n",
      "Processing image: frame_066.jpg, shape: (720, 1280, 3)\n",
      "Input data shape (NCHW): (1, 3, 720, 1280)\n",
      "After reshape dets shape: (33, 5)\n",
      "After reshape labels shape: (33,)\n"
     ]
    }
   ],
   "source": [
    "from mmengine.structures import InstanceData\n",
    "from mmdet.structures import DetDataSample\n",
    "from mmdet.visualization import DetLocalVisualizer\n",
    "from mmdet.datasets import CocoDataset\n",
    "\n",
    "import tritonclient.http as httpclient\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Create Triton client\n",
    "client = httpclient.InferenceServerClient(\"localhost:8000\")\n",
    "\n",
    "# Initialize visualizer with COCO classes\n",
    "visualizer = DetLocalVisualizer()\n",
    "visualizer.dataset_meta = CocoDataset.METAINFO\n",
    "\n",
    "input_dir = \"./video_frames\"\n",
    "output_dir = \"./output_frames1\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Normalization values (COCO mean and std)\n",
    "mean = np.array([123.675, 116.28, 103.53], dtype=np.float32).reshape(3,1,1)\n",
    "std = np.array([58.395, 57.12, 57.375], dtype=np.float32).reshape(3,1,1)\n",
    "\n",
    "# Process images\n",
    "for img_name in sorted(os.listdir(input_dir)):\n",
    "    if not img_name.lower().endswith(\".jpg\"):\n",
    "        continue\n",
    "    img_path = os.path.join(input_dir, img_name)\n",
    "    image = mmcv.imread(img_path)\n",
    "\n",
    "    print(f\"Processing image: {img_name}, shape: {image.shape}\")\n",
    "\n",
    "    # Normalize input image as model expects\n",
    "    input_data = (image.transpose(2,0,1).astype(np.float32) - mean) / std\n",
    "    input_data = input_data[None]  # add batch dimension\n",
    "\n",
    "    print(f\"Input data shape (NCHW): {input_data.shape}\")\n",
    "\n",
    "    # Prepare input for Triton\n",
    "    inputs = [httpclient.InferInput(\"input\", input_data.shape, \"FP32\")]\n",
    "    inputs[0].set_data_from_numpy(input_data)\n",
    "\n",
    "    # Prepare output requests\n",
    "    outputs = [\n",
    "        httpclient.InferRequestedOutput(\"dets\"),\n",
    "        httpclient.InferRequestedOutput(\"labels\")\n",
    "    ]\n",
    "\n",
    "    # Perform inference\n",
    "    response = client.infer(\n",
    "        model_name=\"faster_rcnn\",\n",
    "        inputs=inputs,\n",
    "        outputs=outputs\n",
    "    )\n",
    "\n",
    "    # Extract output arrays\n",
    "    dets = response.as_numpy(\"dets\")\n",
    "    labels = response.as_numpy(\"labels\")\n",
    "\n",
    "    #print(\"Raw dets from Triton:\", dets)\n",
    "    #print(\"Raw labels from Triton:\", labels)\n",
    "\n",
    "    # Flatten batch and detection dims\n",
    "    dets = dets.reshape(-1, dets.shape[-1])\n",
    "    labels = labels.reshape(-1)\n",
    "\n",
    "    print(\"After reshape dets shape:\", dets.shape)\n",
    "    print(\"After reshape labels shape:\", labels.shape)\n",
    "\n",
    "    # Filter out detections with zero or negative score\n",
    "    valid_mask = dets[:, 4] > 0.35\n",
    "    dets = dets[valid_mask]\n",
    "    labels = labels[valid_mask].astype(np.int64)\n",
    "\n",
    "    #print(\"Filtered dets:\", dets)\n",
    "    #print(\"Filtered labels:\", labels)\n",
    "\n",
    "    pred_instances = InstanceData()\n",
    "\n",
    "    if dets.size == 0:\n",
    "        print(\"No valid detections for this image.\")\n",
    "        pred_instances.bboxes = np.empty((0,4), dtype=np.float32)\n",
    "        pred_instances.scores = np.empty((0,), dtype=np.float32)\n",
    "        pred_instances.labels = np.empty((0,), dtype=np.int64)\n",
    "    else:\n",
    "        pred_instances.bboxes = dets[:, :4]\n",
    "        pred_instances.scores = dets[:, 4]\n",
    "        pred_instances.labels = labels\n",
    "\n",
    "    data_sample = DetDataSample()\n",
    "    data_sample.pred_instances = pred_instances\n",
    "\n",
    "    out_file = os.path.join(output_dir, img_name)\n",
    "    visualizer.add_datasample(\n",
    "        name=img_name,\n",
    "        image=image,\n",
    "        data_sample=data_sample,\n",
    "        draw_gt=False,\n",
    "        draw_pred=True,\n",
    "        show=False,\n",
    "        out_file=out_file\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aedf922-5ad9-4bf8-a5ea-923c9f3f9037",
   "metadata": {},
   "source": [
    "![f1](./output_frames1/frame_009.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b8ebe81c-c38b-44ac-b602-33f8a5876b96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/workspace\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0dd51739-fb27-4dba-90be-de69c132666f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "benchmark.ipynb  configs\t       model_repository  output_models\n",
      "checkpoints\t consolidated.ipynb    optimize1.ipynb\t temp\n",
      "config.pbtxt\t create_model_repo.sh  output_frames\t video_frames\n",
      "config.yaml\t example.ipynb\t       output_frames1\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "308f28cb-cfc1-478b-bf18-6bff7c409296",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
